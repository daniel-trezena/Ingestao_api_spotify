{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniel-trezena/Ingestao_api_spotify/blob/main/Teste_Spark_Autoglass_Daniel_Trezena.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "580dd39c-f066-4c32-af47-648eb71f5918",
      "metadata": {
        "tags": [],
        "id": "580dd39c-f066-4c32-af47-648eb71f5918"
      },
      "source": [
        "# Teste: Consumo de Dados da Api do Spotify para analises sobre artistas e músicas.\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Avaliar conhecimentos nas linguagens Python e SQL e na engine de processamento Apache Spark.\n",
        "\n",
        "## Descrição\n",
        "\n",
        "Dado um conjunto de dados de músicas e artistas disponíveis em uma API pública, implemente um pipeline de processamento de dados com PySpark que realiza as seguintes operações:\n",
        "\n",
        "* Consuma a API e extraia as informações de músicas e artistas dos seguintes genêros(\"Rock Nacional\", \"Piseiro/Arrocha\" e \"Pop Internacional\";\n",
        "\n",
        "* Armazene os dados em formato parquet, particionando por artista;\n",
        "\n",
        "* Crie um dataframe com o endpoint \"Get Artist\"\n",
        "* Crie um dataframe com o endpoint \"Get Artist's Albums\" e traga as músicas dos álbuns que estão no endpoint \"Get Album Tracks\".\n",
        "* Crie um dataframe com o endpoint \"Get Current User's Playlists\"\n",
        "\n",
        "* Crie uma tabela temporária em PySpark a partir do DataFrame de músicas dos artistas;\n",
        "* Crie uma tabela temporária em Pyspark a partir do Dataframe de Playlists\n",
        "\n",
        "* Execute uma consulta SQL que retorna os artistas do endpoint \"Get Artist\" que estão nas Playlists, ordenados por ordem alfabética.\n",
        "* Crie um Dataframe com o resultado da consulta e salve em parquet\n",
        "\n",
        ".\n",
        "\n",
        "-------\n",
        "\n",
        "Documentação da Api para consulta:\n",
        "```\n",
        "https://developer.spotify.com/documentation/web-api/\n",
        "```\n",
        "\n",
        "Para criar um Access Token na Spotify API, você precisa seguir os seguintes passos:\n",
        "\n",
        "Acesse o Dashboard da API Spotify:\n",
        "```\n",
        "https://developer.spotify.com/dashboard/login\n",
        "```\n",
        "1. Faça login com sua conta do Spotify ou crie uma nova conta, caso ainda não tenha.\n",
        "2. Crie um novo aplicativo clicando no botão \"Create an App\" e preencha as informações necessárias.\n",
        "3. Após criar o aplicativo, você será direcionado para a página do aplicativo, onde poderá encontrar sua Client ID e Client Secret. Anote essas informações, pois elas serão necessárias para a autenticação.\n",
        "4. Para gerar o Access Token, você precisará fazer uma solicitação GET/POST para o endpoint de autorização da API, passando sua Client ID e Client Secret como parâmetros. Você pode usar ferramentas como o Postman para realizar essa solicitação.\n",
        "5. O endpoint de autorização irá retornar um Access Token que você pode utilizar para fazer requisições à API Spotify.\n",
        "\n",
        "------------\n",
        "\n",
        "\n",
        "## Atenção\n",
        "\n",
        "- Leia a documentação dos endpoints para a extração dos dados, em alguns podem possuir número máximo de itens a serem retornados.\n",
        "\n",
        "### Para realizar esta tarefa, os candidatos devem ter conhecimento em:\n",
        "\n",
        "- PySpark (Spark SQL, Spark DataFrames);\n",
        "- Consumo de API REST;\n",
        "- armazenamento de dados;\n",
        "- Transformações e consultas SQL em PySpark.\n",
        "-------------\n",
        "## Entregando o desafio\n",
        "\n",
        "Faça uma cópia do desafio antes de começar a fazer o desafio e depois exporte para enviar!\n",
        "\n",
        "Concluindo todos os passos informados, basta salvar o arquivo .ipynb do notebook e zipar juntamente com os parquet das tabelas, postar no seu github e enviar o link para ricardo.suhete@autoglass.com.br\n",
        "\n",
        "A entrega da tarefa termina 7 dias após o recebimento deste notebook. Após o prazo será entendindo que o condidato desistiu da vaga.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac91e04c",
      "metadata": {
        "id": "ac91e04c"
      },
      "source": [
        "-----------------------------------------------\n",
        "### Caso não consiga rodar o spark no colab execute os comandos abaixo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a1cb6c40-3073-43b0-b7f4-95e7c9dd8245",
      "metadata": {
        "tags": [],
        "id": "a1cb6c40-3073-43b0-b7f4-95e7c9dd8245",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c91132b3-ccd6-4001-9073-63689787ad7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: spark-3.3.1-bin-hadoop3.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.1-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "99b7ca01",
      "metadata": {
        "id": "99b7ca01"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0829960a",
      "metadata": {
        "id": "0829960a"
      },
      "source": [
        "---------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalação das bibliotecas"
      ],
      "metadata": {
        "id": "clkiGkiVxtNx"
      },
      "id": "clkiGkiVxtNx"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "!pip install -q unidecode\n",
        "!pip install -q pyspark"
      ],
      "metadata": {
        "id": "Vl_ks0r9x9jQ"
      },
      "id": "Vl_ks0r9x9jQ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importação das bibliotecas**"
      ],
      "metadata": {
        "id": "kA0_FgF5Y3GJ"
      },
      "id": "kA0_FgF5Y3GJ"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "id": "g7iTLTJh_YJn"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "import unidecode\n",
        "import base64\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "      .master(\"local[1]\") \\\n",
        "      .appName(\"Teste_Spark_Autoglass_candidatos\") \\\n",
        "      .getOrCreate()\n",
        "from pyspark.sql.types import StructType, StringType"
      ],
      "id": "g7iTLTJh_YJn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requisição do Token"
      ],
      "metadata": {
        "id": "06pF23qt7dug"
      },
      "id": "06pF23qt7dug"
    },
    {
      "cell_type": "code",
      "source": [
        "client_id = userdata.get('Client_ID')\n",
        "client_secret = userdata.get('Client_secret')"
      ],
      "metadata": {
        "id": "8nFZEWF863GR"
      },
      "id": "8nFZEWF863GR",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_token():\n",
        "  auth_string = client_id + \":\" + client_secret\n",
        "  auth_bytes = auth_string.encode(\"ascii\")\n",
        "\n",
        "  base64_bytes = base64.b64encode(auth_bytes)\n",
        "  auth_base64 = base64_bytes.decode('ascii')\n",
        "\n",
        "  url = \"https://accounts.spotify.com/api/token\"\n",
        "  headers = {\n",
        "      \"Authorization\" : \"Basic \" + auth_base64,\n",
        "      \"Content-Type\" : \"application/x-www-form-urlencoded\"\n",
        "  }\n",
        "  data = {\"grant_type\": \"client_credentials\"}\n",
        "  result = requests.request('POST', url=url, headers=headers, data=data)\n",
        "  token = result.json()[\"access_token\"]\n",
        "  return token"
      ],
      "metadata": {
        "id": "dTkWnhvFztle"
      },
      "id": "dTkWnhvFztle",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = get_token()"
      ],
      "metadata": {
        "id": "9_MurmeM9NxT"
      },
      "id": "9_MurmeM9NxT",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requisição de dados de músicas e artistas dos seguintes genêros(\"Rock Nacional\", \"Piseiro/Arrocha\" e \"Pop Internacional\""
      ],
      "metadata": {
        "id": "KukT31IPVcDG"
      },
      "id": "KukT31IPVcDG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurando headers para requisições\n",
        "headers = {\n",
        "    \"Authorization\": \"Bearer \" + token,\n",
        "    \"Accept\": \"application/json\"\n",
        "}"
      ],
      "metadata": {
        "id": "1274UFnTW6FH"
      },
      "id": "1274UFnTW6FH",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generos = [\"rock nacional\", \"piseiro/arrocha\", \"pop internacional\"]\n",
        "\n",
        "for genero in generos:\n",
        "\n",
        "  # Variáveis para paginação\n",
        "  offset = 0\n",
        "  limit = 50\n",
        "  musicas_lista = []\n",
        "\n",
        "  while True:\n",
        "      # Parâmetros\n",
        "      url = \"https://api.spotify.com/v1/search\"\n",
        "      params = {\n",
        "          \"q\": f\"genre:{genero}\",\n",
        "          \"type\": \"track\",\n",
        "          \"limit\": limit,\n",
        "          \"offset\": offset,\n",
        "      }\n",
        "\n",
        "      # Fazer requisição\n",
        "      resposta = requests.get(url, params=params, headers=headers)\n",
        "\n",
        "      # Extração dos dados\n",
        "      musicas = resposta.json()[\"tracks\"][\"items\"]\n",
        "\n",
        "      # Extrair informações\n",
        "      for musica in musicas:\n",
        "        musica_dict = {\n",
        "          \"Nome\": musica[\"name\"],\n",
        "          \"Artista\": musica[\"artists\"][0][\"name\"],\n",
        "          \"Álbum\": musica[\"album\"][\"name\"],\n",
        "          \"Link\": musica[\"external_urls\"][\"spotify\"],\n",
        "      }\n",
        "        musicas_lista.append(musica_dict)\n",
        "\n",
        "      # Verificar se há mais resultados\n",
        "      if resposta.json()[\"tracks\"][\"next\"] is None:\n",
        "          break\n",
        "\n",
        "      # Atualizar offset\n",
        "      offset += limit\n",
        "\n",
        "df_musicas = spark.createDataFrame(musicas_lista)\n",
        "df_musicas.show()"
      ],
      "metadata": {
        "id": "ldxnMWw5lZfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62d2b967-8b62-4c31-dd8f-09be557d0651"
      },
      "id": "ldxnMWw5lZfx",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+--------------------+--------------------+\n",
            "|         Artista|                Link|                Nome|               Álbum|\n",
            "+----------------+--------------------+--------------------+--------------------+\n",
            "|     Ana Castela|https://open.spot...|Solteiro Forçado ...|Solteiro Forçado ...|\n",
            "|     Ana Castela|https://open.spot...|Tô Voltando - (Bo...|Tô Voltando (Boia...|\n",
            "|   Bomba Estéreo|https://open.spot...|     Internacionales|                 Ayo|\n",
            "|     Ana Castela|https://open.spot...| Fronteira - Ao Vivo|Boiadeira Interna...|\n",
            "|     Ana Castela|https://open.spot...|Aqui Tem Alguém -...|Boiadeira Interna...|\n",
            "|El Gran Silencio|https://open.spot...|Super Riddim Inte...|Super Riddim Inte...|\n",
            "|     Ana Castela|https://open.spot...| Fronteira - Ao Vivo|Fronteira: Boiade...|\n",
            "|     Darío Gómez|https://open.spot...|         Sobreviviré|El Rey del Despec...|\n",
            "|     Darío Gómez|https://open.spot...|      Entre Comillas|El Rey del Despec...|\n",
            "|     Ana Castela|https://open.spot...|Alerta de Golpe -...|Boiadeira Interna...|\n",
            "|     Ana Castela|https://open.spot...|   Não Vai Ver Nunca|Não Vai Ver Nunca...|\n",
            "|     Ana Castela|https://open.spot...|Só Não Deixa Saud...|Boiadeira Interna...|\n",
            "|     Darío Gómez|https://open.spot...|     Nadie Es Eterno|El Rey del Despec...|\n",
            "|      Juan Magán|https://open.spot...|       Internacional|                 4.0|\n",
            "|     Darío Gómez|https://open.spot...|Por Las Calles De...|El Rey del Despec...|\n",
            "|     Ana Castela|https://open.spot...|Amizade Ou O Que ...|Boiadeira Interna...|\n",
            "|     Darío Gómez|https://open.spot...|          Corazonada|El Rey del Despec...|\n",
            "|  Antonio Orozco|https://open.spot...|         Ya Lo Sabes|Renovatio (Versio...|\n",
            "|     Ana Castela|https://open.spot...|Morreu de Ana Cas...|Boiadeira Interna...|\n",
            "|     Darío Gómez|https://open.spot...|       Aquí Sobro Yo|El Rey del Despec...|\n",
            "+----------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Armazenamento dos dados em formato parquet, particionando por artista"
      ],
      "metadata": {
        "id": "UGGuoVtX_0tZ"
      },
      "id": "UGGuoVtX_0tZ"
    },
    {
      "cell_type": "code",
      "source": [
        "df_musicas.write.option(\"header\",True).partitionBy(\"Artista\").mode(\"overwrite\").parquet(\"parquet_track\")"
      ],
      "metadata": {
        "id": "D_ss4jvA3WUH"
      },
      "id": "D_ss4jvA3WUH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataframe com os dados do endpoint \"Get Artist\""
      ],
      "metadata": {
        "id": "-j01Grx5cqcc"
      },
      "id": "-j01Grx5cqcc"
    },
    {
      "cell_type": "code",
      "source": [
        "artist = \"4fdCGYM7dtJLa3LvR1ccto?si=WP9igjJ9Te2yqsAm12WkKw\"\n",
        "url = f\"https://api.spotify.com/v1/artists/{artist}\"\n",
        "resposta = requests.get(url, headers=headers)"
      ],
      "metadata": {
        "id": "U-1KpDH_cuix"
      },
      "id": "U-1KpDH_cuix",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artista_dict = json.dumps(resposta.json())\n",
        "df_artista = spark.read.json(spark.sparkContext.parallelize([artista_dict]))\n",
        "df_artista.show(truncate=False)"
      ],
      "metadata": {
        "id": "OtJqGrsb4BPP"
      },
      "id": "OtJqGrsb4BPP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataframe com os dados do endpoint \"Get Artist's Albums\""
      ],
      "metadata": {
        "id": "-xOd6AuVy2ae"
      },
      "id": "-xOd6AuVy2ae"
    },
    {
      "cell_type": "code",
      "source": [
        "url = f\"https://api.spotify.com/v1/artists/{artist}/albums\"\n",
        "resposta = requests.get(url, headers=headers)\n",
        "resposta_dict = json.dumps(resposta.json())\n",
        "df_artista_album = spark.read.json(spark.sparkContext.parallelize([resposta_dict]))"
      ],
      "metadata": {
        "id": "7QjWPVMay040"
      },
      "id": "7QjWPVMay040",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_artista_album.show()"
      ],
      "metadata": {
        "id": "uIADEnToKXyu"
      },
      "id": "uIADEnToKXyu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Músicas dos álbuns que estão no endpoint \"Get Album Tracks\""
      ],
      "metadata": {
        "id": "WWRK8UILSq5_"
      },
      "id": "WWRK8UILSq5_"
    },
    {
      "cell_type": "code",
      "source": [
        "album_id = \"4aawyAB9vmqN3uQ7FjRGTy\"\n",
        "url = f\"https://api.spotify.com/v1/albums/{album_id}/tracks\"\n",
        "params = {\n",
        "          \"market\": \"ES\",\n",
        "          \"limit\": 50,\n",
        "          \"offset\": 0,\n",
        "      }\n",
        "\n",
        "# Fazer requisição\n",
        "resposta = requests.get(url, params=params, headers=headers)\n",
        "\n",
        "# Extração dos dados\n",
        "musicas = resposta.json()[\"items\"]\n",
        "musicas_lista_album = []\n",
        "  # Extrair informações\n",
        "for musica in musicas:\n",
        "  musica_dict = {\n",
        "      \"disc_Number\": musica[\"disc_number\"],\n",
        "      \"nome\": musica[\"name\"],\n",
        "      \"artista\": musica[\"artists\"][0][\"name\"],\n",
        "      \"link\": musica[\"uri\"],\n",
        "      \"track_number\": musica[\"track_number\"]\n",
        "    }\n",
        "  musicas_lista_album.append(musica_dict)\n",
        "\n",
        "df_album_tracks = spark.createDataFrame(musicas_lista_album)\n",
        "df_album_tracks.show(truncate=False)"
      ],
      "metadata": {
        "id": "KUZpkp-hSpY3"
      },
      "id": "KUZpkp-hSpY3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataframe com o endpoint \"Get Current User's Playlists\""
      ],
      "metadata": {
        "id": "H9Hr9SCi2P7I"
      },
      "id": "H9Hr9SCi2P7I"
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://api.spotify.com/v1/users/314f34uytt2dd3qhlunzx6cs6kpq/playlists\"\n",
        "\n",
        "params = {\n",
        "          \"limit\": 20,\n",
        "          \"offset\": 0,\n",
        "      }\n",
        "\n",
        "# Fazer requisição\n",
        "resposta = requests.get(url, params=params, headers=headers)\n",
        "data = resposta.json()\n",
        "# Extraia os dados desejados\n",
        "playlists = []\n",
        "for item in data[\"items\"]:\n",
        "  playlists.append({\n",
        "      \"id\": item[\"id\"],\n",
        "      \"name\": item[\"name\"],\n",
        "      \"description\": item[\"description\"],\n",
        "      \"image_url\": item[\"images\"][0][\"url\"],\n",
        "      \"num_tracks\": item[\"tracks\"][\"total\"],\n",
        "      \"public\": item[\"public\"],\n",
        "      \"collaborative\": item[\"collaborative\"]\n",
        "    })\n",
        "df_playlists = spark.createDataFrame(playlists)\n",
        "df_playlists.show(truncate=False)"
      ],
      "metadata": {
        "id": "-eshHghO2VyK"
      },
      "id": "-eshHghO2VyK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tabela temporária em PySpark a partir do DataFrame de músicas dos artistas"
      ],
      "metadata": {
        "id": "X98AA36NcyC9"
      },
      "id": "X98AA36NcyC9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria a tabela temporária de musicas de artistas\n",
        "df_musicas.createOrReplaceTempView(\"musicas_artist\")\n",
        "\n",
        "# Consulta a tabela temporária e mostrando\n",
        "spark.sql(\"\"\"SELECT * FROM musicas_artist\"\"\").show()\n"
      ],
      "metadata": {
        "id": "p4cTdX7pcy01"
      },
      "id": "p4cTdX7pcy01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tabela temporária em Pyspark a partir do Dataframe de Playlists"
      ],
      "metadata": {
        "id": "RZqJYqKTeFgM"
      },
      "id": "RZqJYqKTeFgM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria a tabela temporária de musicas de artistas\n",
        "df_playlists.createOrReplaceTempView(\"playlists\")\n",
        "\n",
        "# Consulta a tabela temporária e mostrando\n",
        "spark.sql(\"\"\"SELECT * FROM playlists\"\"\").show()"
      ],
      "metadata": {
        "id": "rfYs9TSceNBU"
      },
      "id": "rfYs9TSceNBU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SQL que retorna os artistas do endpoint \"Get Artist\" que estão nas Playlists, ordenados por ordem alfabética."
      ],
      "metadata": {
        "id": "XYlIRJ7-9xmO"
      },
      "id": "XYlIRJ7-9xmO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buscando as musicas da playlist"
      ],
      "metadata": {
        "id": "9biGJTYSd3jj"
      },
      "id": "9biGJTYSd3jj"
    },
    {
      "cell_type": "code",
      "source": [
        "lista_id_playlist = df_playlists.select('id').collect()\n",
        "lista_id_playlist = [row[\"id\"] for row in lista_id_playlist]\n",
        "\n",
        "for id in lista_id_playlist:\n",
        "  url = f\"https://api.spotify.com/v1/playlists/{id}/tracks\"\n",
        "  musicas = []\n",
        "  # Fazer requisição\n",
        "  resposta = requests.get(url, headers=headers)\n",
        "  for item in resposta.json()[\"items\"]:\n",
        "    musica = {\n",
        "      \"id\": item[\"track\"][\"id\"],\n",
        "      \"musica\": item[\"track\"][\"name\"],\n",
        "      \"artista\": item[\"track\"][\"artists\"][0][\"name\"],\n",
        "      \"album\": item[\"track\"][\"album\"][\"name\"]\n",
        "    }\n",
        "    musicas.append(musica)\n",
        "df_playlists_musicas = spark.createDataFrame(musicas)\n",
        "df_playlists_musicas.show(truncate=False)\n",
        "df_playlists_musicas.createOrReplaceTempView(\"playlists_musicas\")"
      ],
      "metadata": {
        "id": "g2WSyZmB9112"
      },
      "id": "g2WSyZmB9112",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQL das tabelas"
      ],
      "metadata": {
        "id": "KjDfk6mld98H"
      },
      "id": "KjDfk6mld98H"
    },
    {
      "cell_type": "code",
      "source": [
        "df_consulta = spark.sql(\"\"\"SELECT a.artista FROM musicas_artist A INNER JOIN playlists_musicas B on A.artista = B.artista ORDER BY artista\"\"\")"
      ],
      "metadata": {
        "id": "_cWeVTAFeARI"
      },
      "id": "_cWeVTAFeARI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_consulta.show(50)"
      ],
      "metadata": {
        "id": "_XDVvehaqfOv"
      },
      "id": "_XDVvehaqfOv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataframe com o resultado da consulta"
      ],
      "metadata": {
        "id": "-LYT1RwQ_EN9"
      },
      "id": "-LYT1RwQ_EN9"
    },
    {
      "cell_type": "code",
      "source": [
        "df_consulta.write.option(\"header\",True).mode(\"overwrite\").parquet(\"consulta_sql\")"
      ],
      "metadata": {
        "id": "Fg3S0XvT_GN5"
      },
      "id": "Fg3S0XvT_GN5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "a45cd9dd122d240dcc4ef38faedf9d2d3fd8f7b31d6f5582a2663b9810b40f8f"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}